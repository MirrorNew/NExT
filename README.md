# NExT
Optimization problems are commonly present in various scenarios, and Large Language Models (LLMs) demonstrate their problem-solving abilities in OR problem formulation and resolution. However, currently the vast majority of OR problem benchmarks cannot meet complex real-world situations, especially in the areas of long text redundancy and nonlinear problems with data sparsity.

In this article, we propose the NExT benchmark, which is a benchmark for solving end-to-end optimization problems using human readable inputs and outputs. NExT contains a wealth of optimization problems, including long and difficult linear problems with corpus redundancy and a variety of nonlinear types of problems, which can comprehensively evaluate the solving ability of LLM. In addition, NExT also includes reference code after modeling. In order to address the scarcity of data and the low difficulty of existing problems in the OR problem during dataset construction, we further proposed a data synthesis method called NETA. NETA first extensively collects selected OR questions, and then we solve them through manual modeling. We then enhance and expand the constraints for questions that are not difficult enough, and inject redundant real-world corpus.

On this basis, in order to better solve such problems, we propose the multi-agent framework of NORA. For the long-term difficulty problem, we first use sentence by sentence detection to prevent the illusion of LLM detecting element errors. Afterwards, we will use modeling experts for modeling. Unlike other agents, we use additional auxiliary modeling agents to update the modeling results, allowing NORA to have a better code alignment mechanism for nonlinear parts.

We extensively evaluated the optimization generalization ability of NORA and compared methods on 10 real datasets. A large number of experimental results have shown that NORA can model and solve various types of optimization problems, especially in long-term and nonlinear problems. Compared with the most advanced prompt based methods, the average solution accuracy has been improved by 7.00%, and it surpasses or approaches fine-tuning methods on most datasets. This code can be applied to[https://github.com/MirrorNew/NExT/](https://github.com/MirrorNew/NExT/) get.
